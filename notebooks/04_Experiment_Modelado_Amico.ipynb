{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8c8d50e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de librerias\n",
    "# ------------------\n",
    "# Librerias de uso general\n",
    "import holidays\n",
    "from google.cloud import storage\n",
    "\n",
    "# Manejo de datos\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import kagglehub\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import OneClassSVM  # Importación para OC-SVM\n",
    "from sklearn.neighbors import LocalOutlierFactor # Importación para LOF\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import f1_score, mean_squared_error\n",
    "from sklearn.metrics import classification_report\n",
    "from math import sqrt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import boxcox\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Visualización\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Estadística y series temporales\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# Se importan las funciones\n",
    "from sklearn.metrics import  mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7a1a5a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 0. configuración ----------\n",
    "CSV_PATH = \"/Users/angeleduardogamarrarios/Repositorio_UDEM/MLops_AMICO/data/costs.csv\"       # ajusta si hace falta\n",
    "TEST_DAYS = 60               # últimos N días para test\n",
    "RND_ITER = 12                # RandomizedSearchCV iteraciones (ajusta)\n",
    "TS_SPLITS = 3                # TimeSeriesSplit folds (ajusta)\n",
    "PERM_REPEATS = 10            # permutación (ajusta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "419b6812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Relational Database Service($)</th>\n",
       "      <th>EC2-Instances($)</th>\n",
       "      <th>FSx($)</th>\n",
       "      <th>Elastic File System($)</th>\n",
       "      <th>EC2-Other($)</th>\n",
       "      <th>CloudWatch($)</th>\n",
       "      <th>S3($)</th>\n",
       "      <th>Elastic Load Balancing($)</th>\n",
       "      <th>Backup($)</th>\n",
       "      <th>Key Management Service($)</th>\n",
       "      <th>DataSync($)</th>\n",
       "      <th>Secrets Manager($)</th>\n",
       "      <th>Resilience Hub($)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-06-01</th>\n",
       "      <td>31.851525</td>\n",
       "      <td>4.612654</td>\n",
       "      <td>12.472440</td>\n",
       "      <td>1.789663</td>\n",
       "      <td>0.611443</td>\n",
       "      <td>0.036701</td>\n",
       "      <td>1.156349</td>\n",
       "      <td>2.160000</td>\n",
       "      <td>0.281071</td>\n",
       "      <td>0.234161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-02</th>\n",
       "      <td>61.039787</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.460864</td>\n",
       "      <td>1.789663</td>\n",
       "      <td>0.322181</td>\n",
       "      <td>0.016653</td>\n",
       "      <td>1.126354</td>\n",
       "      <td>2.160000</td>\n",
       "      <td>0.281071</td>\n",
       "      <td>0.235058</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-03</th>\n",
       "      <td>71.416393</td>\n",
       "      <td>63.161250</td>\n",
       "      <td>12.654853</td>\n",
       "      <td>1.790544</td>\n",
       "      <td>5.613880</td>\n",
       "      <td>0.429317</td>\n",
       "      <td>1.119325</td>\n",
       "      <td>2.160042</td>\n",
       "      <td>0.281071</td>\n",
       "      <td>0.240077</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-04</th>\n",
       "      <td>54.833184</td>\n",
       "      <td>68.402379</td>\n",
       "      <td>12.658942</td>\n",
       "      <td>1.791199</td>\n",
       "      <td>5.682819</td>\n",
       "      <td>0.459109</td>\n",
       "      <td>1.116106</td>\n",
       "      <td>2.160139</td>\n",
       "      <td>0.281314</td>\n",
       "      <td>0.238019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-05</th>\n",
       "      <td>53.620439</td>\n",
       "      <td>68.712852</td>\n",
       "      <td>12.661379</td>\n",
       "      <td>1.791209</td>\n",
       "      <td>5.743577</td>\n",
       "      <td>0.433357</td>\n",
       "      <td>1.111825</td>\n",
       "      <td>2.160105</td>\n",
       "      <td>0.281270</td>\n",
       "      <td>0.241016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-13</th>\n",
       "      <td>427.332194</td>\n",
       "      <td>84.055196</td>\n",
       "      <td>15.981744</td>\n",
       "      <td>20.057154</td>\n",
       "      <td>7.017312</td>\n",
       "      <td>14.886703</td>\n",
       "      <td>3.324044</td>\n",
       "      <td>2.178117</td>\n",
       "      <td>4.093720</td>\n",
       "      <td>0.355898</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-14</th>\n",
       "      <td>434.475518</td>\n",
       "      <td>83.762637</td>\n",
       "      <td>16.053639</td>\n",
       "      <td>20.057536</td>\n",
       "      <td>7.172683</td>\n",
       "      <td>14.094290</td>\n",
       "      <td>3.322075</td>\n",
       "      <td>2.176548</td>\n",
       "      <td>4.093781</td>\n",
       "      <td>0.355868</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-15</th>\n",
       "      <td>451.056891</td>\n",
       "      <td>84.366709</td>\n",
       "      <td>16.084850</td>\n",
       "      <td>20.057790</td>\n",
       "      <td>8.126316</td>\n",
       "      <td>15.385274</td>\n",
       "      <td>3.316396</td>\n",
       "      <td>2.194784</td>\n",
       "      <td>4.093839</td>\n",
       "      <td>0.355790</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006030</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-16</th>\n",
       "      <td>455.461320</td>\n",
       "      <td>83.318072</td>\n",
       "      <td>16.014588</td>\n",
       "      <td>20.058303</td>\n",
       "      <td>7.776150</td>\n",
       "      <td>14.029922</td>\n",
       "      <td>3.310646</td>\n",
       "      <td>2.178596</td>\n",
       "      <td>4.093945</td>\n",
       "      <td>0.355925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-17</th>\n",
       "      <td>449.999272</td>\n",
       "      <td>56.562941</td>\n",
       "      <td>15.586052</td>\n",
       "      <td>20.058707</td>\n",
       "      <td>2.303717</td>\n",
       "      <td>2.890993</td>\n",
       "      <td>3.323908</td>\n",
       "      <td>2.161670</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.355538</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>351 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Relational Database Service($)  EC2-Instances($)     FSx($)  \\\n",
       "date                                                                      \n",
       "2024-06-01                       31.851525          4.612654  12.472440   \n",
       "2024-06-02                       61.039787               NaN  12.460864   \n",
       "2024-06-03                       71.416393         63.161250  12.654853   \n",
       "2024-06-04                       54.833184         68.402379  12.658942   \n",
       "2024-06-05                       53.620439         68.712852  12.661379   \n",
       "...                                    ...               ...        ...   \n",
       "2025-05-13                      427.332194         84.055196  15.981744   \n",
       "2025-05-14                      434.475518         83.762637  16.053639   \n",
       "2025-05-15                      451.056891         84.366709  16.084850   \n",
       "2025-05-16                      455.461320         83.318072  16.014588   \n",
       "2025-05-17                      449.999272         56.562941  15.586052   \n",
       "\n",
       "            Elastic File System($)  EC2-Other($)  CloudWatch($)     S3($)  \\\n",
       "date                                                                        \n",
       "2024-06-01                1.789663      0.611443       0.036701  1.156349   \n",
       "2024-06-02                1.789663      0.322181       0.016653  1.126354   \n",
       "2024-06-03                1.790544      5.613880       0.429317  1.119325   \n",
       "2024-06-04                1.791199      5.682819       0.459109  1.116106   \n",
       "2024-06-05                1.791209      5.743577       0.433357  1.111825   \n",
       "...                            ...           ...            ...       ...   \n",
       "2025-05-13               20.057154      7.017312      14.886703  3.324044   \n",
       "2025-05-14               20.057536      7.172683      14.094290  3.322075   \n",
       "2025-05-15               20.057790      8.126316      15.385274  3.316396   \n",
       "2025-05-16               20.058303      7.776150      14.029922  3.310646   \n",
       "2025-05-17               20.058707      2.303717       2.890993  3.323908   \n",
       "\n",
       "            Elastic Load Balancing($)  Backup($)  Key Management Service($)  \\\n",
       "date                                                                          \n",
       "2024-06-01                   2.160000   0.281071                   0.234161   \n",
       "2024-06-02                   2.160000   0.281071                   0.235058   \n",
       "2024-06-03                   2.160042   0.281071                   0.240077   \n",
       "2024-06-04                   2.160139   0.281314                   0.238019   \n",
       "2024-06-05                   2.160105   0.281270                   0.241016   \n",
       "...                               ...        ...                        ...   \n",
       "2025-05-13                   2.178117   4.093720                   0.355898   \n",
       "2025-05-14                   2.176548   4.093781                   0.355868   \n",
       "2025-05-15                   2.194784   4.093839                   0.355790   \n",
       "2025-05-16                   2.178596   4.093945                   0.355925   \n",
       "2025-05-17                   2.161670        NaN                   0.355538   \n",
       "\n",
       "            DataSync($)  Secrets Manager($)  Resilience Hub($)  \n",
       "date                                                            \n",
       "2024-06-01          NaN            0.000255                0.0  \n",
       "2024-06-02          NaN            0.000295                NaN  \n",
       "2024-06-03          NaN            0.000225                NaN  \n",
       "2024-06-04          NaN            0.000225                NaN  \n",
       "2024-06-05          NaN            0.000525                NaN  \n",
       "...                 ...                 ...                ...  \n",
       "2025-05-13          NaN            0.000450                NaN  \n",
       "2025-05-14          NaN            0.000370                NaN  \n",
       "2025-05-15          NaN            0.006030                NaN  \n",
       "2025-05-16          NaN            0.000260                NaN  \n",
       "2025-05-17          NaN            0.000100                NaN  \n",
       "\n",
       "[351 rows x 13 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e2545613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas: 351 Columnas: ['Relational Database Service($)', 'EC2-Instances($)', 'FSx($)', 'Elastic File System($)', 'EC2-Other($)', 'CloudWatch($)', 'S3($)', 'Elastic Load Balancing($)', 'Backup($)', 'Key Management Service($)', 'DataSync($)', 'Secrets Manager($)', 'Resilience Hub($)']\n"
     ]
    }
   ],
   "source": [
    "# ---------- 1. carga y limpieza básica ----------\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "# eliminar fila de \"Service total\" si existe\n",
    "df = df[df['Service'] != 'Service total']\n",
    "df = df.drop('Total costs($)', axis=1)\n",
    "\n",
    "# convertir columna de fecha en indice\n",
    "df['Service'] = pd.to_datetime(df['Service'])\n",
    "df = df.rename(columns={'Service':'date'}).sort_values('date').set_index('date')\n",
    "\n",
    "# forzar numérico y revisar columnas\n",
    "df = df.apply(pd.to_numeric, errors='coerce')\n",
    "num_cols = df.columns.tolist()\n",
    "\n",
    "print(\"Filas:\", len(df), \"Columnas:\", num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f22d9e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resumen estadístico:\n",
      "                                count       mean        std           min  \\\n",
      "Relational Database Service($)  351.0  97.240692  87.975006  1.491792e+01   \n",
      "EC2-Instances($)                329.0  71.525192  25.109641  5.154986e-01   \n",
      "FSx($)                          351.0  14.678272   1.855596  1.208052e+01   \n",
      "Elastic File System($)          351.0   8.064240   6.456387  1.786584e+00   \n",
      "EC2-Other($)                    351.0   6.076750   2.900253  3.117944e-01   \n",
      "CloudWatch($)                   351.0   4.398582   7.681060  3.109096e-03   \n",
      "S3($)                           351.0   2.218248   0.787167  1.023371e+00   \n",
      "Elastic Load Balancing($)       351.0   2.162289   0.004710  2.160000e+00   \n",
      "Backup($)                       350.0   1.514773   1.210465  2.810710e-01   \n",
      "Key Management Service($)       351.0   0.260617   0.032317  2.263914e-01   \n",
      "DataSync($)                     119.0   0.286251   1.415347  6.440000e-08   \n",
      "Secrets Manager($)              349.0   0.000513   0.000527  2.000000e-05   \n",
      "Resilience Hub($)                 3.0   0.000000   0.000000  0.000000e+00   \n",
      "\n",
      "                                      25%        50%         75%         max  \n",
      "Relational Database Service($)  41.109960  66.762613  118.507451  455.461320  \n",
      "EC2-Instances($)                60.758766  68.402379   95.067461  100.737059  \n",
      "FSx($)                          12.584705  15.468255   16.056011   18.491514  \n",
      "Elastic File System($)           2.040983   4.627442   14.108374   20.584791  \n",
      "EC2-Other($)                     5.541606   6.124120    7.267743   11.823171  \n",
      "CloudWatch($)                    0.478766   0.682977    1.661212   25.383237  \n",
      "S3($)                            1.693569   2.084439    3.082417    3.540238  \n",
      "Elastic Load Balancing($)        2.160033   2.160623    2.162270    2.194784  \n",
      "Backup($)                        0.322099   1.043619    2.500407    4.093945  \n",
      "Key Management Service($)        0.237089   0.258728    0.267448    0.356186  \n",
      "DataSync($)                      0.000001   0.000001    0.001859    8.782443  \n",
      "Secrets Manager($)               0.000245   0.000455    0.000640    0.006030  \n",
      "Resilience Hub($)                0.000000   0.000000    0.000000    0.000000  \n",
      "\n",
      "Skewness (top):\n",
      "Secrets Manager($)                6.825494\n",
      "DataSync($)                       5.243936\n",
      "Elastic Load Balancing($)         3.825244\n",
      "Relational Database Service($)    1.866276\n",
      "CloudWatch($)                     1.677079\n",
      "Key Management Service($)         1.537350\n",
      "Elastic File System($)            0.664392\n",
      "Backup($)                         0.622538\n",
      "S3($)                             0.119986\n",
      "Resilience Hub($)                 0.000000\n",
      "dtype: float64\n",
      "\n",
      "Media por día de la semana (muestra):\n",
      "          Relational Database Service($)  EC2-Instances($)     FSx($)  \\\n",
      "date                                                                    \n",
      "Friday                        104.490301         76.534417  14.801883   \n",
      "Monday                         97.532270         75.251444  14.722385   \n",
      "Saturday                       90.899097         44.656602  14.535091   \n",
      "Sunday                         83.598953         75.433716  14.472918   \n",
      "Thursday                      103.113998         76.944815  14.770521   \n",
      "\n",
      "          Elastic File System($)  EC2-Other($)  CloudWatch($)     S3($)  \\\n",
      "date                                                                      \n",
      "Friday                  8.218541      7.052756       4.532564  2.239331   \n",
      "Monday                  7.949294      6.826152       4.525775  2.209111   \n",
      "Saturday                8.179670      4.083944       3.875943  2.207464   \n",
      "Sunday                  7.941768      3.811028       3.811151  2.189945   \n",
      "Thursday                8.026860      6.897890       4.715092  2.233260   \n",
      "\n",
      "          Elastic Load Balancing($)  Backup($)  Key Management Service($)  \\\n",
      "date                                                                        \n",
      "Friday                     2.163086   1.543027                   0.261761   \n",
      "Monday                     2.162876   1.479395                   0.260807   \n",
      "Saturday                   2.161187   1.527428                   0.260784   \n",
      "Sunday                     2.160560   1.518090                   0.258952   \n",
      "Thursday                   2.163299   1.514082                   0.260705   \n",
      "\n",
      "          DataSync($)  Secrets Manager($)  Resilience Hub($)  \n",
      "date                                                          \n",
      "Friday       1.264603            0.000579                NaN  \n",
      "Monday       0.073895            0.000552                0.0  \n",
      "Saturday     0.053987            0.000396                0.0  \n",
      "Sunday       0.000705            0.000420                NaN  \n",
      "Thursday     0.001682            0.000621                0.0  \n"
     ]
    }
   ],
   "source": [
    "# ---------- 2. EDA rápido (resumen + skew + patrón semanal) ----------\n",
    "print(\"\\nResumen estadístico:\")\n",
    "print(df.describe().T)\n",
    "\n",
    "skewness = df.skew().sort_values(ascending=False)\n",
    "print(\"\\nSkewness (top):\")\n",
    "print(skewness.head(10))\n",
    "\n",
    "weekly_mean = df.groupby(df.index.day_name()).mean()\n",
    "print(\"\\nMedia por día de la semana (muestra):\")\n",
    "print(weekly_mean.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "97db7068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 3. imputación ----------\n",
    "# Strategy: cambiar a 0 los valores nulos\n",
    "df_imputed = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "80fcfa13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box-Cox aplicado a Secrets Manager($), lambda=0.3130\n",
      "Box-Cox aplicado a DataSync($), lambda=-0.7391\n",
      "Box-Cox aplicado a Elastic Load Balancing($), lambda=-693.3143\n",
      "Box-Cox aplicado a Relational Database Service($), lambda=-0.0614\n",
      "Box-Cox aplicado a CloudWatch($), lambda=0.0712\n",
      "Box-Cox aplicado a Key Management Service($), lambda=-4.2383\n"
     ]
    }
   ],
   "source": [
    "# ---------- 4. Box-Cox selectivo para normalizar las varibles ----------\n",
    "# Aplicar Box-Cox solo a columnas muy sesgadas (skew > 1)\n",
    "skewed_cols = skewness[skewness > 1].index.tolist()\n",
    "df_bc = df_imputed.copy()\n",
    "\n",
    "for c in skewed_cols:\n",
    "    # Box-Cox exige valores > 0. si hay ceros o negativos shift pequeño\n",
    "    min_val = df_bc[c].min()\n",
    "    shift = 0.0 if min_val > 0 else abs(min_val) + 1e-6\n",
    "    try:\n",
    "        transformed, lam = boxcox(df_bc[c] + shift)\n",
    "        df_bc[c] = transformed\n",
    "        print(f\"Box-Cox aplicado a {c}, lambda={lam:.4f}\")\n",
    "    except Exception as e:\n",
    "        # fallback log1p si falla\n",
    "        df_bc[c] = np.log1p(df_bc[c] + shift)\n",
    "        print(f\"Box-Cox falló en {c}, aplicado log1p\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f3da2cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 5. normalización por día de la semana ----------\n",
    "df_bc['day_of_week'] = df_bc.index.day_name()\n",
    "scaled = df_bc.copy()\n",
    "features = [c for c in num_cols]  # lista de features reales\n",
    "\n",
    "for day in scaled['day_of_week'].unique():\n",
    "    mask = scaled['day_of_week'] == day\n",
    "    if mask.sum() < 2:\n",
    "        # si no hay suficientes ejemplos para el día, omitir\n",
    "        continue\n",
    "    scaler = StandardScaler()\n",
    "    scaled.loc[mask, features] = scaler.fit_transform(scaled.loc[mask, features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9a1c6299",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_mapper = {\n",
    "    'Service': 'fecha',\n",
    "    'Relational Database Service($)': 'rds',\n",
    "    'EC2-Instances($)': 'ec2',\n",
    "    'FSx($)': 'fsx',\n",
    "    'Elastic File System($)': 'efs',\n",
    "    'EC2-Other($)': 'ec2_other',\n",
    "    'CloudWatch($)': 'cloudwatch',\n",
    "    'Elastic Load Balancing($)': 'elb',\n",
    "    'S3($)': 's3',\n",
    "    'Backup($)': 'backup',\n",
    "    'Key Management Service($)': 'kms',\n",
    "    'DataSync($)': 'data_sync',\n",
    "    'Secrets Manager($)': 'secrets_manager',\n",
    "    'Resilience Hub($)': 'resiliency',\n",
    "    'Total costs($)': 'total_costs'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ecde7843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapeo de columnas \n",
    "scaled.rename(columns=column_mapper, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3a04092f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train shape: (290, 13), Test shape: (61, 13)\n"
     ]
    }
   ],
   "source": [
    "# ---------- 6. división train/test temporal ----------\n",
    "split_date = scaled.index.max() - pd.Timedelta(days=TEST_DAYS)\n",
    "train_df = scaled[scaled.index < split_date].drop(columns=['day_of_week'])\n",
    "test_df = scaled[scaled.index >= split_date].drop(columns=['day_of_week'])\n",
    "\n",
    "X_train = train_df.values\n",
    "X_test = test_df.values\n",
    "cols = train_df.columns.tolist()\n",
    "\n",
    "print(f\"\\nTrain shape: {X_train.shape}, Test shape: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2b53947e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "\n",
      "Mejores parámetros (RandomizedSearch):\n",
      "{'n_estimators': 50, 'max_samples': 0.9, 'max_features': 0.7, 'contamination': 0.001}\n",
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n",
      "\n",
      "Mejores parámetros (GridSearch):\n",
      "{'contamination': 0.0005, 'max_features': 0.7, 'max_samples': 1.0, 'n_estimators': 10}\n"
     ]
    }
   ],
   "source": [
    "# ---------- 7. búsqueda de hiperparámetros ----------\n",
    "# scoring personalizado: media de decision_function (cuanto mayor, mejor)\n",
    "def scoring_fn(estimator, X, y=None):\n",
    "    return float(np.mean(estimator.decision_function(X)))\n",
    "\n",
    "iso = IsolationForest(random_state=42)\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 200, 300],\n",
    "    'max_samples': [0.5, 0.7, 0.9, 'auto'],\n",
    "    'contamination': [0.001, 0.005, 0.01, 0.02, 0.05],\n",
    "    'max_features': [0.5, 0.7, 1.0]\n",
    "}\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=TS_SPLITS)\n",
    "rnd = RandomizedSearchCV(iso, param_distributions=param_dist, n_iter=RND_ITER,\n",
    "                         cv=tscv, random_state=42, n_jobs=-1, scoring=scoring_fn, verbose=1)\n",
    "rnd.fit(X_train)\n",
    "\n",
    "print(\"\\nMejores parámetros (RandomizedSearch):\")\n",
    "print(rnd.best_params_)\n",
    "\n",
    "# ajustar pequeño grid alrededor del mejor para refinar (GridSearch)\n",
    "best = rnd.best_params_\n",
    "grid = {\n",
    "    'n_estimators': sorted(list({max(10, best['n_estimators']-50), best['n_estimators'], best['n_estimators']+50})),\n",
    "    'max_samples': sorted(list(set([best['max_samples'] if best['max_samples']=='auto' else max(0.1, best['max_samples']-0.1), best['max_samples'], min(1.0, best['max_samples']+0.1)]))),\n",
    "    'contamination': sorted(list({max(0.0005, best['contamination']/2), best['contamination'], min(0.1, best['contamination']*2)})),\n",
    "    'max_features': sorted(list({max(0.1, best['max_features']-0.2), best['max_features'], min(1.0, best['max_features']+0.2)}))\n",
    "}\n",
    "# limpiar valores inválidos\n",
    "grid['max_samples'] = [v for v in grid['max_samples'] if (isinstance(v, str) or (isinstance(v, float) and 0 < v <= 1))]\n",
    "\n",
    "gsearch = GridSearchCV(IsolationForest(random_state=42), param_grid=grid, cv=tscv, n_jobs=-1, scoring=scoring_fn, verbose=1)\n",
    "gsearch.fit(X_train)\n",
    "\n",
    "print(\"\\nMejores parámetros (GridSearch):\")\n",
    "print(gsearch.best_params_)\n",
    "\n",
    "best_model = gsearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6ce20e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Anomalías en test (conteo): 48\n",
      "            anomaly_score  anomaly\n",
      "date                              \n",
      "2025-03-18       0.027744        0\n",
      "2025-03-19       0.031538        0\n",
      "2025-03-20       0.012313        0\n",
      "2025-03-21       0.010773        0\n",
      "2025-03-22       0.057409        0\n",
      "2025-03-23       0.042554        0\n",
      "2025-03-24      -0.001470        1\n",
      "2025-03-25      -0.046853        1\n",
      "2025-03-26       0.009830        0\n",
      "2025-03-27      -0.013589        1\n",
      "\n",
      "Top features por importancia (permutación):\n",
      "data_sync     0.598448\n",
      "ec2           0.573623\n",
      "rds           0.500277\n",
      "ec2_other     0.484483\n",
      "efs           0.447616\n",
      "s3            0.425308\n",
      "backup        0.313089\n",
      "kms           0.256657\n",
      "cloudwatch    0.178152\n",
      "fsx           0.169421\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ---------- 8. predecir y marcar anomalías ----------\n",
    "test_scores = best_model.decision_function(X_test)   # mayor => más normal\n",
    "test_pred = best_model.predict(X_test)                # 1 normal, -1 anomalía\n",
    "test_anomaly = np.where(test_pred == 1, 0, 1)         # 1 = anomalía (más intuitivo)\n",
    "\n",
    "test_out = test_df.copy()\n",
    "test_out['anomaly_score'] = test_scores\n",
    "test_out['anomaly'] = test_anomaly\n",
    "\n",
    "print(\"\\nAnomalías en test (conteo):\", int(test_out['anomaly'].sum()))\n",
    "print(test_out[['anomaly_score','anomaly']].head(10))\n",
    "\n",
    "# ---------- 9. importancia de features (permutación) ----------\n",
    "# Usamos como 'y' las scores del modelo en train y medimos R2 del estimator.decision_function\n",
    "y_train_scores = best_model.decision_function(X_train)\n",
    "\n",
    "def scoring_fn_r2(estimator, X, y):\n",
    "    return r2_score(y, estimator.decision_function(X))\n",
    "\n",
    "perm = permutation_importance(best_model, X_train, y_train_scores, scoring=scoring_fn_r2,\n",
    "                              n_repeats=PERM_REPEATS, random_state=42, n_jobs=-1)\n",
    "perm_importances = pd.Series(perm.importances_mean, index=cols).sort_values(ascending=False)\n",
    "\n",
    "print(\"\\nTop features por importancia (permutación):\")\n",
    "print(perm_importances.head(10))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "46991582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados guardados: test_anomaly_results.csv, feature_importances_permutation.csv\n"
     ]
    }
   ],
   "source": [
    "# ---------- 10. exportar resultados ----------\n",
    "test_out.to_csv(\"test_anomaly_results.csv\")\n",
    "perm_importances.to_csv(\"feature_importances_permutation.csv\")\n",
    "print(\"\\nResultados guardados: test_anomaly_results.csv, feature_importances_permutation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "85a91f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  1  1  1  1  1 -1 -1  1 -1 -1 -1  1 -1  1  1  1 -1  1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1]\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "# Guardar el modelo entrenado\n",
    "joblib.dump(best_model, 'modelo_entrenado_amico_1.pkl')\n",
    "modelo_cargado = joblib.load('modelo_entrenado_amico_1.pkl')\n",
    "pred = modelo_cargado.predict(X_test)\n",
    "print(pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLops_AMICO (3.12.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

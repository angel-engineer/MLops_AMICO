{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95de1e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de librerias\n",
    "# ------------------\n",
    "# Librerias de uso general\n",
    "import holidays\n",
    "from google.cloud import storage\n",
    "\n",
    "# Manejo de datos\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import kagglehub\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Visualización\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Estadística y series temporales\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# Se importan las funciones\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ea3a890",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_mapper = {\n",
    "    'Service': 'fecha',\n",
    "    'Relational Database Service($)': 'rds',\n",
    "    'EC2-Instances($)': 'ec2',\n",
    "    'FSx($)': 'fsx',\n",
    "    'Elastic File System($)': 'efs',\n",
    "    'EC2-Other($)': 'ec2_other',\n",
    "    'CloudWatch($)': 'cloudwatch',\n",
    "    'Elastic Load Balancing($)': 'elb',\n",
    "    'S3($)': 's3',\n",
    "    'Backup($)': 'backup',\n",
    "    'Key Management Service($)': 'kms',\n",
    "    'DataSync($)': 'data_sync',\n",
    "    'Secrets Manager($)': 'secrets_manager',\n",
    "    'Resilience Hub($)': 'resiliency',\n",
    "    'Total costs($)': 'total_costs'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661e10de",
   "metadata": {},
   "source": [
    "Carga de los Datos\n",
    "Se hace la carga de los datos desde la ruta Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "783f1dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Service</th>\n",
       "      <th>Relational Database Service($)</th>\n",
       "      <th>EC2-Instances($)</th>\n",
       "      <th>FSx($)</th>\n",
       "      <th>Elastic File System($)</th>\n",
       "      <th>EC2-Other($)</th>\n",
       "      <th>CloudWatch($)</th>\n",
       "      <th>S3($)</th>\n",
       "      <th>Elastic Load Balancing($)</th>\n",
       "      <th>Backup($)</th>\n",
       "      <th>Key Management Service($)</th>\n",
       "      <th>DataSync($)</th>\n",
       "      <th>Secrets Manager($)</th>\n",
       "      <th>Resilience Hub($)</th>\n",
       "      <th>Total costs($)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Service total</td>\n",
       "      <td>34131.482733</td>\n",
       "      <td>23531.788153</td>\n",
       "      <td>5152.073356</td>\n",
       "      <td>2830.548352</td>\n",
       "      <td>2132.939335</td>\n",
       "      <td>1543.902136</td>\n",
       "      <td>778.604880</td>\n",
       "      <td>758.963353</td>\n",
       "      <td>530.170434</td>\n",
       "      <td>91.476443</td>\n",
       "      <td>34.06381</td>\n",
       "      <td>0.178930</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71516.191916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-06-01</td>\n",
       "      <td>31.851525</td>\n",
       "      <td>4.612654</td>\n",
       "      <td>12.472440</td>\n",
       "      <td>1.789663</td>\n",
       "      <td>0.611443</td>\n",
       "      <td>0.036701</td>\n",
       "      <td>1.156349</td>\n",
       "      <td>2.160000</td>\n",
       "      <td>0.281071</td>\n",
       "      <td>0.234161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.206262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-06-02</td>\n",
       "      <td>61.039787</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.460864</td>\n",
       "      <td>1.789663</td>\n",
       "      <td>0.322181</td>\n",
       "      <td>0.016653</td>\n",
       "      <td>1.126354</td>\n",
       "      <td>2.160000</td>\n",
       "      <td>0.281071</td>\n",
       "      <td>0.235058</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.431926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-06-03</td>\n",
       "      <td>71.416393</td>\n",
       "      <td>63.161250</td>\n",
       "      <td>12.654853</td>\n",
       "      <td>1.790544</td>\n",
       "      <td>5.613880</td>\n",
       "      <td>0.429317</td>\n",
       "      <td>1.119325</td>\n",
       "      <td>2.160042</td>\n",
       "      <td>0.281071</td>\n",
       "      <td>0.240077</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>158.866978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-06-04</td>\n",
       "      <td>54.833184</td>\n",
       "      <td>68.402379</td>\n",
       "      <td>12.658942</td>\n",
       "      <td>1.791199</td>\n",
       "      <td>5.682819</td>\n",
       "      <td>0.459109</td>\n",
       "      <td>1.116106</td>\n",
       "      <td>2.160139</td>\n",
       "      <td>0.281314</td>\n",
       "      <td>0.238019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>147.623435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Service  Relational Database Service($)  EC2-Instances($)  \\\n",
       "0  Service total                    34131.482733      23531.788153   \n",
       "1     2024-06-01                       31.851525          4.612654   \n",
       "2     2024-06-02                       61.039787               NaN   \n",
       "3     2024-06-03                       71.416393         63.161250   \n",
       "4     2024-06-04                       54.833184         68.402379   \n",
       "\n",
       "        FSx($)  Elastic File System($)  EC2-Other($)  CloudWatch($)  \\\n",
       "0  5152.073356             2830.548352   2132.939335    1543.902136   \n",
       "1    12.472440                1.789663      0.611443       0.036701   \n",
       "2    12.460864                1.789663      0.322181       0.016653   \n",
       "3    12.654853                1.790544      5.613880       0.429317   \n",
       "4    12.658942                1.791199      5.682819       0.459109   \n",
       "\n",
       "        S3($)  Elastic Load Balancing($)   Backup($)  \\\n",
       "0  778.604880                 758.963353  530.170434   \n",
       "1    1.156349                   2.160000    0.281071   \n",
       "2    1.126354                   2.160000    0.281071   \n",
       "3    1.119325                   2.160042    0.281071   \n",
       "4    1.116106                   2.160139    0.281314   \n",
       "\n",
       "   Key Management Service($)  DataSync($)  Secrets Manager($)  \\\n",
       "0                  91.476443     34.06381            0.178930   \n",
       "1                   0.234161          NaN            0.000255   \n",
       "2                   0.235058          NaN            0.000295   \n",
       "3                   0.240077          NaN            0.000225   \n",
       "4                   0.238019          NaN            0.000225   \n",
       "\n",
       "   Resilience Hub($)  Total costs($)  \n",
       "0                0.0    71516.191916  \n",
       "1                0.0       55.206262  \n",
       "2                NaN       79.431926  \n",
       "3                NaN      158.866978  \n",
       "4                NaN      147.623435  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Datos con corte a Abril usar: \"costs.csv\"\n",
    "\n",
    "df = pd.read_csv('/Users/angeleduardogamarrarios/Repositorio_UDEM/MLops_AMICO/data/costs.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33c425db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapeo de columnas \n",
    "df.rename(columns=column_mapper, inplace=True)\n",
    "# Elimina la fila con índice 0 y ka columna total_cost\n",
    "df = df.drop(0, axis=0)\n",
    "df = df.drop('total_costs', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cde6646",
   "metadata": {},
   "source": [
    "# Prepocesar datos\n",
    "\n",
    "Para nuestro caso de analisis vamos a aplicar una normalizacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f7ff710",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separar las variables continuas de las demás\n",
    "df_continuas=df[[\"rds\",\n",
    "                       \"ec2\",\n",
    "                       \"fsx\",\n",
    "                       \"efs\",\n",
    "                       \"ec2_other\",\n",
    "                       \"cloudwatch\",\n",
    "                       \"s3\",\n",
    "                       \"elb\",\n",
    "                       \"backup\",\n",
    "                       \"kms\",\n",
    "                       \"data_sync\",\n",
    "                       \"secrets_manager\",\n",
    "                       \"resiliency\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d615f2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EL conjunto de datos se divide en una proporción de 60% (Entrenamiento), 20% (Validación) y 20% (Prueba).\n",
    "X_train_val, X_test = train_test_split(df_continuas, test_size=0.2, random_state=42)\n",
    "X_train, X_val = train_test_split(X_train_val, test_size=0.25, random_state=42) # 0.25 * 0.80 = 0.20 (20% para Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e736020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Media de 'rds' en X_train original: 96.0687\n",
      "Media de 'rds' en X_train escalado: -0.0000\n",
      "--------------------------------------------------\n",
      "✅ Pipeline y datos escalados listos. El preprocesador se guardó en: ./data/\n"
     ]
    }
   ],
   "source": [
    "# Normalizar los datos \n",
    "preprocessor_pipeline = Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor_pipeline.fit(X_train)\n",
    "\n",
    "X_train_scaled = preprocessor_pipeline.transform(X_train)\n",
    "X_val_scaled = preprocessor_pipeline.transform(X_val)\n",
    "X_test_scaled = preprocessor_pipeline.transform(X_test)\n",
    "\n",
    "# 4. Verificación y Persistencia (MLOps)\n",
    "print(f\"Media de 'rds' en X_train original: {X_train['rds'].mean():.4f}\")\n",
    "print(f\"Media de 'rds' en X_train escalado: {X_train_scaled[:, X_train.columns.get_loc('rds')].mean():.4f}\") # La media debe ser cercana a 0\n",
    "\n",
    "# Guardar el Pipeline (¡Esto es clave para el MLOps!)\n",
    "# Debes guardar el objeto preprocessor_pipeline para usarlo en producción\n",
    "# cuando llegue un nuevo dato de vino.\n",
    "\n",
    "OUTPUT_DIR = \"./data/\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "with open(os.path.join(OUTPUT_DIR, \"preprocessor_pipeline.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(preprocessor_pipeline, f)\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(f\"✅ Pipeline y datos escalados listos. El preprocesador se guardó en: {OUTPUT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39343c67",
   "metadata": {},
   "source": [
    "Isolation Forest (El Enfoque Robusto)\n",
    "El Isolation Forest es rápido, escalable y muy robusto para datos multivariados con muchos outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4fbfea79",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- anomaly_iso_forest\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     21\u001b[39m df_[\u001b[33m'\u001b[39m\u001b[33manomaly_iso_forest\u001b[39m\u001b[33m'\u001b[39m] = iso_forest.predict(X_train)\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# Obtener la 'Puntuación de Anomalía' (cuanto menor, más anómalo)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m df_[\u001b[33m'\u001b[39m\u001b[33mscore_iso_forest\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43miso_forest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Mostrar los días anómalos\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Anomalías detectadas por Isolation Forest (ejemplo) ---\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repositorio_UDEM/MLops_AMICO/.venv/lib/python3.12/site-packages/sklearn/ensemble/_iforest.py:474\u001b[39m, in \u001b[36mIsolationForest.decision_function\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    426\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    427\u001b[39m \u001b[33;03mAverage anomaly score of X of the base classifiers.\u001b[39;00m\n\u001b[32m    428\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    469\u001b[39m \u001b[33;03m        model.decision_function(X)\u001b[39;00m\n\u001b[32m    470\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    471\u001b[39m \u001b[38;5;66;03m# We subtract self.offset_ to make 0 be the threshold value for being\u001b[39;00m\n\u001b[32m    472\u001b[39m \u001b[38;5;66;03m# an outlier:\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m474\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscore_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m - \u001b[38;5;28mself\u001b[39m.offset_\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repositorio_UDEM/MLops_AMICO/.venv/lib/python3.12/site-packages/sklearn/ensemble/_iforest.py:519\u001b[39m, in \u001b[36mIsolationForest.score_samples\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    477\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    478\u001b[39m \u001b[33;03mOpposite of the anomaly score defined in the original paper.\u001b[39;00m\n\u001b[32m    479\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    516\u001b[39m \u001b[33;03m        model.score(X)\u001b[39;00m\n\u001b[32m    517\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    518\u001b[39m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m519\u001b[39m X = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    520\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    521\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    522\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtree_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    524\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    525\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    526\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    528\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._score_samples(X)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repositorio_UDEM/MLops_AMICO/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:2929\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2845\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvalidate_data\u001b[39m(\n\u001b[32m   2846\u001b[39m     _estimator,\n\u001b[32m   2847\u001b[39m     /,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2853\u001b[39m     **check_params,\n\u001b[32m   2854\u001b[39m ):\n\u001b[32m   2855\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Validate input data and set or check feature names and counts of the input.\u001b[39;00m\n\u001b[32m   2856\u001b[39m \n\u001b[32m   2857\u001b[39m \u001b[33;03m    This helper function should be used in an estimator that requires input\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2927\u001b[39m \u001b[33;03m        validated.\u001b[39;00m\n\u001b[32m   2928\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2929\u001b[39m     \u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_estimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2930\u001b[39m     tags = get_tags(_estimator)\n\u001b[32m   2931\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m tags.target_tags.required:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repositorio_UDEM/MLops_AMICO/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:2787\u001b[39m, in \u001b[36m_check_feature_names\u001b[39m\u001b[34m(estimator, X, reset)\u001b[39m\n\u001b[32m   2784\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[32m   2785\u001b[39m     message += \u001b[33m\"\u001b[39m\u001b[33mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m2787\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[31mValueError\u001b[39m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- anomaly_iso_forest\n"
     ]
    }
   ],
   "source": [
    "# --- CONFIGURACIÓN DEL MODELO ---\n",
    "\n",
    "# El parámetro 'contamination' es crucial.\n",
    "# Define la proporción esperada de anomalías (ej. 1% a 5% del total de días)\n",
    "# Si no estás seguro, empieza con un valor conservador (0.01).\n",
    "contamination_factor = 0.01\n",
    "\n",
    "# Inicializar el modelo\n",
    "iso_forest = IsolationForest(\n",
    "    n_estimators=100,\n",
    "    contamination=contamination_factor,\n",
    "    random_state=42,\n",
    "    n_jobs=-1  # Usa todos los núcleos\n",
    ")\n",
    "\n",
    "# Entrenar el modelo (No supervisado: no necesita etiquetas)\n",
    "iso_forest.fit(X_train)\n",
    "\n",
    "# Predecir las anomalías: -1 para anomalía, 1 para dato normal\n",
    "df_=X_train\n",
    "df_['anomaly_iso_forest'] = iso_forest.predict(X_train)\n",
    "\n",
    "# Obtener la 'Puntuación de Anomalía' (cuanto menor, más anómalo)\n",
    "df_['score_iso_forest'] = iso_forest.decision_function(X_train)\n",
    "\n",
    "# Mostrar los días anómalos\n",
    "print(\"\\n--- Anomalías detectadas por Isolation Forest (ejemplo) ---\")\n",
    "anomalies_if = df_[df_['anomaly_iso_forest'] == -1]\n",
    "print(f\"Total de anomalías detectadas: {len(anomalies_if)}\")\n",
    "print(anomalies_if.head())\n",
    "# Nota: El umbral para la detección es ajustado por el 'contamination' que elegiste."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLops_AMICO (3.12.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
